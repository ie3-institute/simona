akka {

  loggers = ["akka.event.slf4j.Slf4jLogger"]
  # Options: OFF, ERROR, WARNING, INFO, DEBUG
  loglevel = "debug"
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"

  actor {
    # provider is now set programmatically
    #provider = local

    allow-java-serialization = on
    # Java serialization is far from optimal, thus we get warnings for
    # every encoded message. Turn off, since this is annoying
    warn-about-java-serializer-usage = off

    serializers {
      java = "akka.serialization.JavaSerializer"
      proto = "akka.remote.serialization.ProtobufSerializer"
    }

    serialization-bindings {
      "java.lang.String" = java
      "com.google.protobuf.Message" = proto
    }

    // akka supervision strategy for failure handling
    // https://doc.akka.io/docs/akka/current/fault-tolerance.html
    // and https://doc.akka.io/docs/akka/current/general/supervision.html#user-guardian
    guardian-supervisor-strategy = "akka.actor.StoppingSupervisorStrategy"

  }

  # For the sample, just bind to loopback and do not allow access from the network
  remote.artery {
    enabled = on
    transport = tcp
    # port overridden upon start
    canonical.port = 2551
    canonical.hostname = 127.0.0.1

    # Since grid initialization messages can become several 100kb big, they sometimes don't fit into the buffer frame.
    # Here, we the enlarge buffer size.
    advanced {
      # default size: 256 KiB
      maximum-frame-size = 512 KiB
      # default size: 2 MiB
      maximum-large-frame-size = 2 MiB
    }
  }

  cluster {
    # after cluster initialization, this is the number of initial members required in the cluster, before the members
    # can be declared "Up". Setting this to the actual number of nodes prevents the need to rebalance shards later
    min-nr-of-members = 3
    seed-nodes = [
      "akka://simona@127.0.0.1:2551",
      "akka://simona@127.0.0.1:2552",
      "akka://simona@127.0.0.1:2553"
      ]

    # set to on if multiple nodes are run in one JVM
    jmx.multi-mbeans-in-same-jvm = on

    # auto downing is NOT safe for production deployments.
    # you may want to use it during development, read more about it in the docs.
    #auto-down-unreachable-after = 10s

    sharding {
      # Rebalance check is performed periodically with this interval.
      rebalance-interval = 60 s

      # Number of shards used to compute shard ids. This value must be
      # the same for all nodes in the cluster and that is verified by
      # configuration check when joining. Changing the value requires
      # stopping all nodes in the cluster. Rule of thumb: Ten times
      # the number of nodes (according to Akka docs).
      number-of-shards = 30

      # When this is set to 'on' the active entity actors will automatically be restarted
      # upon Shard restart. i.e. if the Shard is started on a different ShardRegion
      # due to rebalance or crash.
      remember-entities = off
      # default: ddata
      #remember-entities-store = ddata
      # No need to remember entities on disk
      #distributed-data.durable.keys = []

      # No passivation, we need all entities until the end.
      # If this is turned on, we need remembering entities to be turned on.
      passivate-idle-entity-after = off
    }
  }

  coordinated-shutdown {
    phases {
      actor-system-terminate {
        timeout = 500 s // increased to allow file operations to terminate!
        depends-on = [before-actor-system-terminate]
      }
    }

  }
}